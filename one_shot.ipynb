{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based losely on:\n",
    " - https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/\n",
    " -  https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    " - https://github.com/harvardnlp/sent-summary\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihai/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 92579\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import nltk\n",
    "import process_text\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "src_txt_length = 100\n",
    "sum_txt_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # encoder input model\n",
    "    inputs = Input(shape=(src_txt_length,))\n",
    "    encoder1 = Embedding(vocab_size, 128)(inputs)\n",
    "    encoder2 = LSTM(128)(encoder1)\n",
    "    encoder3 = RepeatVector(sum_txt_length)(encoder2)\n",
    "    # decoder output model\n",
    "    decoder1 = LSTM(128, return_sequences=True)(encoder3)\n",
    "    outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder1)\n",
    "    # tie it together\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 128)          128000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 1000)          129000    \n",
      "=================================================================\n",
      "Total params: 520,168\n",
      "Trainable params: 520,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Stories 92579\n"
     ]
    }
   ],
   "source": [
    "stories = data.get_cnn_stories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'story': ['at the start of a big week for the higgs boson the most soughtafter particle in all of physics scientists in illinois said monday that they had crept closer to proving that the particle exists but had been unable to reach a definitive conclusion', 'the scientists outlined their final analysis based on more than years of research and trillion particle collisions using the us department of energys fermilab tevatron collider near batavia illinois whose budgetary woes shut it down last year', 'what is the higgs boson and why is it important', 'their announcement came two days before researchers at the large hadron collider under the alps are due to unveil their latest results at an eagerly awaited seminar at the cern particle physics laboratory in geneva switzerland', 'our data strongly point toward the existence of the higgs boson rob roser a spokesman for one of two independent experiments at the tevatron said in a statement but it will take results from the experiments at the large hadron collider in europe to establish a discovery', 'read more the woman at the edge of physics', 'finding the higgs boson would help explain the origin of mass one of the open questions in physicists current understanding of the way the universe works', 'the particle has been so difficult to pin down that the physicist leon lederman reportedly wanted to call his book the goddamn particle but he truncated that epithet to the god particle which may have helped elevate the particles allure in popular culture', 'more science news from cnn light years', 'the results from the tevatron stemming from the two different experiments suggest that if the higgs boson does exist it would have a mass between and gev about times the mass of the proton', 'before the tevatron closed the experiments there sent beams of particles whizzing around a fourmile circumference in opposite directions traveling at a fraction below the speed of light the particles would crash into each other creating conditions similar to those at the dawn of the universe for scientists to observe', 'but so far neither the results from the us collider experiments nor from the the large hadron collider located feet underneath the border of france and switzerland have enough statistical significance to constitute a discovery', 'it is easier to look for a friends face in a sports stadium filled with people than to search for a higgslike event among trillions of collisions said luciano ristori a physicist at the us facility', 'attention now turns to the latest analysis of data from the billion european machine the worlds most powerful particle smasher', 'we now have more than double the data we had last year sergio bertolucci the director for research and computing at cern said last month that should be enough to see whether the trends we were seeing in the data are still there or whether theyve gone away its a very exciting time', 'scientists getting clearer picture of god particle'], 'highlights': ['usbased scientists say their data points toward the existence of the higgs boson', 'finding the higgs boson would help explain the origin of mass', 'but the research at the tevatron collider doesnt provide a conclusive answer', 'attention now turns to a seminar wednesday on data from the large hadron collider']}\n"
     ]
    }
   ],
   "source": [
    "print(stories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usbased scientists say their data points toward the existence of the higgs boson', 'finding the higgs boson would help explain the origin of mass', 'but the research at the tevatron collider doesnt provide a conclusive answer', 'attention now turns to a seminar wednesday on data from the large hadron collider']\n"
     ]
    }
   ],
   "source": [
    "print(stories[0]['highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at the start of a big week for the higgs boson the most soughtafter particle in all of physics scientists in illinois said monday that they had crept closer to proving that the particle exists but had been unable to reach a definitive conclusion', 'the scientists outlined their final analysis based on more than years of research and trillion particle collisions using the us department of energys fermilab tevatron collider near batavia illinois whose budgetary woes shut it down last year', 'what is the higgs boson and why is it important', 'their announcement came two days before researchers at the large hadron collider under the alps are due to unveil their latest results at an eagerly awaited seminar at the cern particle physics laboratory in geneva switzerland', 'our data strongly point toward the existence of the higgs boson rob roser a spokesman for one of two independent experiments at the tevatron said in a statement but it will take results from the experiments at the large hadron collider in europe to establish a discovery', 'read more the woman at the edge of physics', 'finding the higgs boson would help explain the origin of mass one of the open questions in physicists current understanding of the way the universe works', 'the particle has been so difficult to pin down that the physicist leon lederman reportedly wanted to call his book the goddamn particle but he truncated that epithet to the god particle which may have helped elevate the particles allure in popular culture', 'more science news from cnn light years', 'the results from the tevatron stemming from the two different experiments suggest that if the higgs boson does exist it would have a mass between and gev about times the mass of the proton', 'before the tevatron closed the experiments there sent beams of particles whizzing around a fourmile circumference in opposite directions traveling at a fraction below the speed of light the particles would crash into each other creating conditions similar to those at the dawn of the universe for scientists to observe', 'but so far neither the results from the us collider experiments nor from the the large hadron collider located feet underneath the border of france and switzerland have enough statistical significance to constitute a discovery', 'it is easier to look for a friends face in a sports stadium filled with people than to search for a higgslike event among trillions of collisions said luciano ristori a physicist at the us facility', 'attention now turns to the latest analysis of data from the billion european machine the worlds most powerful particle smasher', 'we now have more than double the data we had last year sergio bertolucci the director for research and computing at cern said last month that should be enough to see whether the trends we were seeing in the data are still there or whether theyve gone away its a very exciting time', 'scientists getting clearer picture of god particle']\n"
     ]
    }
   ],
   "source": [
    "print(stories[0]['story'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c14e03dbf0f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optionally continue to train with all data, this will likely overfit the training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(one_hot_names, normalized_values,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     batch_size=32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'one_hot_names' is not defined"
     ]
    }
   ],
   "source": [
    "# Optionally continue to train with all data, this will likely overfit the training data.\n",
    "history = model.fit(one_hot_names, normalized_values,\n",
    "                    epochs=10,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters for later use.\n",
    "model.save_weights('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4ce54a883635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
